% Experiment Section
\section{Methods}

\subsection{Data}

We utilized the AML scAtlas~\cite{amlAtlas2024}, a comprehensive resource containing scRNA-seq data from 159 AML patients across multiple studies. From this atlas, we selected five studies representing diverse technical platforms and biological contexts:

\begin{itemize}
    \item \textbf{van\_galen\_2019}~\cite{vangalen2019}: 23,344 cells from AML patients profiled using Seq-Well technology; serves as the gold-standard reference for AML cell type hierarchies
    \item \textbf{jiang\_2020}: 73,810 cells profiled using 10x Genomics Chromium
    \item \textbf{beneyto-calabuig-2023}: 75,372 cells using 10x Genomics Chromium Single Cell 3'
    \item \textbf{velten\_2021}: 4,191 cells using Muta-Seq (mutation tracking + transcriptomics)
    \item \textbf{zhang\_2023}: 75,962 cells from the atlas paper's primary dataset
\end{itemize}

All datasets included expert consensus annotations generated through the atlas pipeline: scVI integration, CellTypist + SingleR + scType consensus, manual marker gene curation, and custom LSC annotation. These annotations served as our reference labels for evaluation.

\subsection{Experiment 1: Annotation Replication}

\subsubsection{SCimilarity Projection}
We projected each dataset independently to SCimilarity's pre-trained latent space~\cite{scimilarity2023} (model version 1.1):
\begin{enumerate}
    \item Extracted raw count matrices from each study
    \item Aligned gene names to SCimilarity's gene order (embedding common genes, zero-padding missing genes)
    \item Computed embeddings in batches of 5,000 cells to manage memory
    \item Generated 384-dimensional latent representations for each cell
\end{enumerate}

\subsubsection{Clustering and Evaluation}
For each study, we performed Leiden clustering~\cite{leiden2019} on SCimilarity embeddings at multiple resolutions (0.1, 0.2, 0.3, 0.4, 0.5) to match the granularity of expert annotations (16 cell types). We computed:

\begin{itemize}
    \item \textbf{Adjusted Rand Index (ARI)}: Measures agreement between cluster assignments and expert labels, correcting for chance
    \item \textbf{Normalized Mutual Information (NMI)}: Quantifies shared information between clusterings
\end{itemize}

Resolution 0.1 was identified as optimal, producing approximately 14--17 clusters per study, closely matching the expert annotation granularity.

\subsection{Experiment 2: Cross-Study Label Transfer}

We evaluated label transfer performance using van\_galen\_2019 as reference (23,344 labeled cells) and the remaining four studies as targets.

\subsubsection{Method 1: Traditional Reference-Based Classification}
Following standard approaches analogous to SingleR~\cite{singleR2019} and Seurat~\cite{seurat2021}:
\begin{enumerate}
    \item Identified common genes between reference and target (typically >15,000 genes)
    \item Normalized both datasets (library size normalization, log transformation)
    \item Selected 2,000 highly variable genes from reference
    \item Trained Random Forest classifier (100 trees, max depth 20) on reference
    \item Predicted cell type labels for target dataset
\end{enumerate}

\subsubsection{Method 2: SCimilarity KNN Transfer}
Leveraging the pre-trained latent space:
\begin{enumerate}
    \item Projected reference cells to SCimilarity space
    \item Projected target cells to SCimilarity space
    \item Performed k-nearest neighbors classification (k=15) in shared latent space
    \item Transferred labels from reference neighbors to target cells
\end{enumerate}

\subsubsection{Evaluation Metrics}
We assessed label transfer quality using:
\begin{itemize}
    \item \textbf{ARI}: Overall agreement with expert target annotations
    \item \textbf{NMI}: Information preservation during transfer
    \item \textbf{Macro F1}: Average F1 score across all cell types (equal weight)
    \item \textbf{Weighted F1}: F1 score weighted by cell type frequency
    \item \textbf{Transfer time}: Computational cost per target dataset
\end{itemize}

Macro F1 is particularly important as it reveals performance on rare cell types (e.g., leukemic stem cells, progenitors) that are often critical for AML biology but constitute a small fraction of cells.

\subsection{Batch Effect Analysis}

To assess whether SCimilarity's latent space provides batch correction, we computed batch mixing scores:
\begin{itemize}
    \item For each cell, identified 30 nearest neighbors in latent space
    \item Counted unique studies represented in each neighborhood
    \item Averaged across all cells (score: 1.0 = no mixing, 5.0 = perfect mixing)
\end{itemize}

\subsection{Computational Environment}

All analyses were performed using Python 3.9 with scanpy~\cite{scanpy2018} (v1.9.3), SCimilarity (v1.1), scikit-learn (v1.3.0), and standard scientific computing libraries. Computations were run on [specify your hardware if relevant].

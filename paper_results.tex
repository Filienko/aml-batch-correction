% Results Section
\section{Results}

\subsection{SCimilarity Embeddings Replicate Expert Annotations with Dataset-Dependent Performance}

We first evaluated whether SCimilarity embeddings with simple Leiden clustering could approximate the complex consensus annotation pipeline used in the AML scAtlas (scVI + CellTypist + SingleR + scType + manual curation).

Table~\ref{tab:per_dataset} shows substantial variation across studies. The highest agreement was achieved on beneyto-calabuig-2023 (ARI=0.623, NMI=0.733), demonstrating that SCimilarity can closely approximate expert consensus on high-quality 10x Genomics data. Moderate agreement was observed for velten\_2021 (ARI=0.436) and zhang\_2023 (ARI=0.398), while van\_galen\_2019 (ARI=0.217) and jiang\_2020 (ARI=0.182) showed lower concordance.

When examining a single study in isolation with optimized clustering parameters (Leiden resolution=0.1), performance improved substantially. For beneyto-calabuig-2023, we achieved ARI=0.702 and NMI=0.786 (Table~\ref{tab:optimized}), approaching the level of agreement typically considered ``good'' for automated annotation methods.

The variation in performance across studies likely reflects differences in data quality, biological heterogeneity, cell type distributions, and annotation consistency rather than fundamental limitations of the foundation model approach. Notably, the atlas paper's own dataset (zhang\_2023) did not achieve the highest agreement, suggesting that dataset-intrinsic factors beyond the annotation source influence automated replication.

\subsection{Optimal Clustering Resolution Matches Expert Granularity}

Resolution sweep analysis (Figure~\ref{fig:resolution}) revealed that optimal performance occurred at resolution 0.1, which produced approximately 17 clusters closely matching the 16 expert-defined cell types (Table~\ref{tab:resolution}). Higher resolutions (0.5--0.8) created excessive fragmentation (35--50 clusters), yielding lower ARI scores. This demonstrates the importance of matching clustering granularity to the reference annotation scheme.

Interestingly, the relationship between cluster number and ARI was not monotonic: resolution 0.1 (17 clusters) outperformed both lower resolutions that merged distinct types and higher resolutions that over-fragmented populations. This suggests an intrinsic biological structure at approximately this granularity that SCimilarity's latent space naturally captures.

\subsection{Intra-Study Baseline Establishes Upper Bound Performance}

Before evaluating cross-study label transfer, we established a performance baseline without batch effects by performing train/test splits within van\_galen\_2019. This isolates method-intrinsic performance from batch-related degradation.

On this within-study split (Table~\ref{tab:intra_study}), both methods achieved strong performance: traditional Random Forest attained ARI=0.691 (5-fold CV), while SCimilarity KNN reached ARI=0.779, representing a 13\% improvement even in the absence of batch effects. This demonstrates that SCimilarity's latent space provides intrinsically better cell type separation compared to normalized gene expression features, independent of batch robustness considerations.

\subsection{Cross-Study Transfer Reveals Dramatic Batch Effect Sensitivity}

We next tested whether SCimilarity's pre-trained latent space enables more robust label transfer compared to traditional reference-based classification. Using van\_galen\_2019 as reference and four independent studies as targets, we compared traditional Random Forest classification on normalized counts versus k-nearest neighbors in SCimilarity space. This cross-study setting introduces batch effects from different sequencing platforms, patient cohorts, and processing protocols.

SCimilarity-based transfer substantially outperformed traditional methods across all metrics (Table~\ref{tab:label_transfer}):

\begin{itemize}
    \item \textbf{Overall accuracy}: ARI increased from 0.430 (traditional) to 0.625 (SCimilarity), a 45\% improvement
    \item \textbf{Rare cell type performance}: Macro F1 more than doubled from 0.315 to 0.670 (+113\%)
    \item \textbf{Information preservation}: NMI improved from 0.506 to 0.644 (+27\%)
\end{itemize}

The dramatic improvement in macro F1 is particularly significant for AML research, where rare populations such as leukemic stem cells and early progenitors are critical for understanding disease biology but constitute a small fraction of cells. Traditional classification methods showed strong bias toward abundant cell types (weighted F1=0.XXX), while SCimilarity maintained balanced performance across rare and common populations.

Per-target analysis (Table~\ref{tab:per_target}) revealed consistent SCimilarity advantages across all four studies, with ARI improvements ranging from 22\% (zhang\_2023) to 138\% (jiang\_2020). Most notably, on beneyto-calabuig-2023, SCimilarity achieved ARI=0.852 compared to traditional methods' 0.614, representing a 39\% improvement. Even on the challenging jiang\_2020 dataset where both methods struggled, SCimilarity more than doubled the macro F1 score (0.585 vs 0.242, +142\%). This cross-study consistency demonstrates the batch-robust nature of the pre-trained latent space.

\subsection{Quantifying Batch Effect Impact: Intra-Study vs Cross-Study Performance}

Comparing intra-study (Table~\ref{tab:intra_study}) and cross-study (Table~\ref{tab:label_transfer}) performance reveals the magnitude of batch effect degradation:

\begin{itemize}
    \item \textbf{Traditional methods}: ARI drops from 0.691 (intra-study) to 0.430 (cross-study), a 38\% decline
    \item \textbf{SCimilarity}: ARI drops from 0.779 (intra-study) to 0.625 (cross-study), a 20\% decline
\end{itemize}

This comparison quantifies SCimilarity's superior batch robustness: while both methods experience performance degradation when transferring across studies, traditional methods lose nearly twice as much accuracy (38\% vs 20\% decline). The pre-trained latent space maintains 80\% of its within-study performance when applied across studies, whereas traditional gene expression features retain only 62\% of their within-study accuracy.

Critically, this batch robustness difference compounds with SCimilarity's intrinsic advantage (13\% better even without batch effects), resulting in the dramatic 45\% improvement observed in cross-study settings. Foundation models provide both better cell type representations AND better batch robustness—a dual advantage for cross-study integration.

\subsection{Computational Considerations}

Traditional classification required 11.4 seconds per target on average, while SCimilarity required 31.6 seconds (2.8× slower). However, this comparison does not account for SCimilarity's key advantage: embedding reusability. Once computed, SCimilarity embeddings enable rapid transfer to any reference via KNN (< 1 second), whereas traditional methods require complete retraining for each reference-target pair. For workflows involving multiple references or iterative refinement, SCimilarity's amortized cost may be favorable.

More critically, for applications where accuracy on rare cell types is paramount—such as identifying therapy-resistant cell populations or early progenitors—the 113\% improvement in macro F1 substantially outweighs the modest increase in computation time.

\subsection{Batch Effects Are Partially but Not Completely Removed}

Analysis of the SCimilarity latent space revealed a batch mixing score of 1.08 out of 5.0 when combining all five studies, indicating that study-of-origin information is largely preserved in the embeddings. This is expected: SCimilarity is pre-trained on diverse datasets to capture biological variation, not explicitly trained for batch correction like scVI.

However, the improved label transfer performance (despite this partial batch signal) suggests that SCimilarity's representations separate biological variation from technical noise more effectively than raw count-based features. The latent space appears to maintain batch identity while enabling better cross-study biological correspondence.

\subsection{Summary}

Our systematic evaluation demonstrates that:

\begin{enumerate}
    \item SCimilarity can approximate complex consensus annotation pipelines (ARI up to 0.70), though performance varies by dataset quality
    \item Even without batch effects (intra-study), SCimilarity provides intrinsically better cell type representations (13\% higher ARI than traditional methods)
    \item When batch effects are introduced (cross-study), traditional methods degrade 38\% while SCimilarity degrades only 20\%—demonstrating superior batch robustness
    \item Foundation model-based label transfer substantially outperforms traditional methods for cross-study annotation, particularly for rare cell types critical to AML biology (macro F1: +113\%)
    \item The pre-trained latent space provides batch-robust representations despite not explicitly performing batch correction
    \item For high-quality datasets, automated foundation model approaches may reduce or eliminate the need for multi-tool consensus and manual curation
\end{enumerate}

These findings position foundation models as a practical tool for automated annotation and cross-study integration, with particular value for rare cell type identification and rapid analysis of new datasets. The dual advantage—better intrinsic representations AND better batch robustness—makes foundation models especially compelling for multi-study meta-analyses and atlas construction.
